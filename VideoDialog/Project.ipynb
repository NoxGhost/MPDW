{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9515d8f2-8d5c-4e18-962d-99015d8540c1",
   "metadata": {},
   "source": [
    "# Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33002c11-93c5-4f22-b619-e696fb4f0df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cluster_name': 'docker-cluster',\n",
      " 'cluster_uuid': 'N4D1rJQtQC-KCHXVHEExZw',\n",
      " 'name': '370b9e54a331',\n",
      " 'tagline': 'The OpenSearch Project: https://opensearch.org/',\n",
      " 'version': {'build_date': '2025-02-27T01:16:47.726162386Z',\n",
      "             'build_hash': '2e4741fb45d1b150aaeeadf66d41445b23ff5982',\n",
      "             'build_snapshot': False,\n",
      "             'build_type': 'tar',\n",
      "             'distribution': 'opensearch',\n",
      "             'lucene_version': '9.12.1',\n",
      "             'minimum_index_compatibility_version': '7.0.0',\n",
      "             'minimum_wire_compatibility_version': '7.10.0',\n",
      "             'number': '2.19.1'}}\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings()  # Suppress self-signed cert warnings\n",
    "\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import requests\n",
    "import pprint as pp\n",
    "\n",
    "host = 'localhost'\n",
    "port = 9200\n",
    "user = 'admin'\n",
    "password = 'MyStr0ng@Pass'\n",
    "index_name = user\n",
    "\n",
    "url = f\"https://{host}:{port}\"\n",
    "\n",
    "try:\n",
    "    res = requests.get(url, auth=HTTPBasicAuth(user, password), verify=False)\n",
    "    pp.pprint(res.json())\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Request failed:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1f4e8-e5b2-44ed-92e4-b9538f9deed0",
   "metadata": {},
   "source": [
    "# Load Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf633922-a158-443d-9588-54f985223474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scripts.parse_activitynet import load_captions\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Get current working directory\n",
    "repo_root = Path().resolve()\n",
    "\n",
    "# Build the relative path to the JSON file\n",
    "json_path = repo_root / \"captions\" / \"train.json\"\n",
    "\n",
    "# Load all captions\n",
    "data = load_captions(str(json_path))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Find videos that mention \"car\"\n",
    "contains_car = df[df['caption'].str.contains(r'\\bcar\\b', case=False, na=False)]\n",
    "car_video_ids = set(contains_car['video_id'])\n",
    "\n",
    "# Step 2: Get videos with more than 8 captions\n",
    "caption_counts = df['video_id'].value_counts()\n",
    "videos_with_8plus = set(caption_counts[caption_counts > 8].index)\n",
    "\n",
    "# Step 3: Intersection → videos that meet both criteria\n",
    "valid_video_ids = list(car_video_ids & videos_with_8plus)\n",
    "\n",
    "# Step 4: Pick just 10 videos from the intersection\n",
    "five_video_ids = valid_video_ids[:10] \n",
    "\n",
    "# Step 5: Get all captions for those 10 videos\n",
    "selected_df = df[df['video_id'].isin(five_video_ids)]\n",
    "\n",
    "# Confirm selection\n",
    "print(f\"Selected {len(selected_df)} captions from 10 videos:\")\n",
    "print(selected_df.groupby(\"video_id\").size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1484d6c8-c171-4159-bbb9-62c85a466e0b",
   "metadata": {},
   "source": [
    "# Open Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c803b7-e567-48c0-8e57-823eb3d28b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "from opensearchpy import OpenSearch\n",
    "from opensearchpy import helpers\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    http_compress = True, # enables gzip compression for request bodies\n",
    "    http_auth = (user, password),\n",
    "    use_ssl = True,\n",
    "    verify_certs = False,\n",
    "    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False\n",
    ")\n",
    "\n",
    "if client.indices.exists(index_name):\n",
    "\n",
    "    resp = client.indices.open(index = index_name)\n",
    "    print(resp)\n",
    "\n",
    "    print('\\n----------------------------------------------------------------------------------- INDEX SETTINGS')\n",
    "    settings = client.indices.get_settings(index = index_name)\n",
    "    pp.pprint(settings)\n",
    "\n",
    "    print('\\n----------------------------------------------------------------------------------- INDEX MAPPINGS')\n",
    "    mappings = client.indices.get_mapping(index = index_name)\n",
    "    pp.pprint(mappings)\n",
    "\n",
    "    print('\\n----------------------------------------------------------------------------------- INDEX #DOCs')\n",
    "    print(client.count(index = index_name))\n",
    "else:\n",
    "    print(\"Index does not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55066869-f5ad-4a68-9f74-cec20d698726",
   "metadata": {},
   "source": [
    "## Close Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f98cfef-c382-47e0-9cfa-8d657050ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = client.indices.close(index = index_name)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ee2b82-1937-4907-bcf5-5d026ef1a26d",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Index creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ffd49a-62f6-44a9-8495-0eff60a49b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_body = {\n",
    "    \"settings\": {\n",
    "        \"index\": {\n",
    "            \"number_of_replicas\": 0,\n",
    "            \"number_of_shards\": 1,\n",
    "            \"refresh_interval\": \"1s\",\n",
    "            \"knn\": \"true\"\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"dynamic\": \"strict\",\n",
    "        \"properties\": {\n",
    "            \"video_id\": {\"type\": \"keyword\"},\n",
    "            \"start\": {\"type\": \"float\"},\n",
    "            \"end\": {\"type\": \"float\"},\n",
    "            \"duration\": {\"type\": \"float\"},\n",
    "            \"caption\": {\"type\": \"text\", \"analyzer\": \"standard\"},\n",
    "            \"video_url\": {\"type\": \"keyword\"},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "if client.indices.exists(index=index_name):\n",
    "    print(\"Index already existed. Nothing to be done.\")\n",
    "else:        \n",
    "    response = client.indices.create(index_name, body=index_body)\n",
    "    print('\\nCreating index:')\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f29b3b-cd42-4ce7-b0e8-abb263b7709d",
   "metadata": {},
   "source": [
    "## Check the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262acbc5-c5e7-42c4-bc08-f8ece0d0ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n----------------------------------------------------------------------------------- INDEX SETTINGS')\n",
    "index_settings = {\n",
    "    \"settings\":{\n",
    "      \"index\":{\n",
    "         \"refresh_interval\" : \"1s\"\n",
    "      }\n",
    "   }\n",
    "}\n",
    "pp.pprint(client.indices.get_alias(index_name))\n",
    "\n",
    "client.indices.put_settings(index = index_name, body = index_settings)\n",
    "settings = client.indices.get_settings(index = index_name)\n",
    "pp.pprint(settings)\n",
    "\n",
    "print('\\n----------------------------------------------------------------------------------- INDEX MAPPINGS')\n",
    "mappings = client.indices.get_mapping(index = index_name)\n",
    "pp.pprint(mappings)\n",
    "\n",
    "print('\\n----------------------------------------------------------------------------------- INDEX #DOCs')\n",
    "print(client.count(index = index_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7d13d-5a5f-40fc-a087-d24f01d1de85",
   "metadata": {},
   "source": [
    "## Index deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30899134-d6fd-4163-b1c3-2d08c4cfba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "This line is here to prevent you from inadvertently deleting data.\n",
    "\n",
    "if client.indices.exists(index=index_name):\n",
    "    # Delete the index.\n",
    "    response = client.indices.delete(\n",
    "        index = index_name\n",
    "    )\n",
    "    print('\\nDeleting index:')\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484661e8-54f3-41f2-8bf3-5385180bb958",
   "metadata": {},
   "source": [
    "# Built-in document tokenizers and analyzers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83775ed4-cebb-4b34-89bf-b44c10244754",
   "metadata": {},
   "outputs": [],
   "source": [
    "anls = {\n",
    "  \"analyzer\": \"whitespace\",\n",
    "  \"text\": \"The car speeds down the highway\"\n",
    "}\n",
    "client.indices.analyze(body=anls, index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e4df3-b24a-4901-aa2b-6ef20f925a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "anls = {\n",
    "  \"analyzer\": \"standard\",\n",
    "  \"text\": \"The car speeds down the highway\"\n",
    "}\n",
    "client.indices.analyze(body=anls, index=index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2e6fca-9166-4c43-9188-d686073819b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in selected_df.iterrows():\n",
    "    moment = {\n",
    "        'video_id': row['video_id'],\n",
    "        'caption': row['caption'],\n",
    "        'start': row['start'],\n",
    "        'end': row['end'],\n",
    "        'duration': row['duration'],\n",
    "        'video_url': row['video_url'],\n",
    "    }\n",
    "    \n",
    "    response = client.index(index=index_name, id=f\"{row['video_id']}_{row['start']}\", body=moment)\n",
    "    print(response['result'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c11953e-baf7-452c-bcfe-11f77c8fca16",
   "metadata": {},
   "source": [
    "## Deleting a single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f79a2b-d68d-4d3a-b7f3-8a849dfe953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "This line is here to prevent you from inadvertently deleting data.\n",
    "\n",
    "response = client.delete(\n",
    "    index = index_name,\n",
    "    id = id\n",
    ")\n",
    "\n",
    "print('\\nDeleting document:')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14e9316-4dbd-4029-bfe8-dbc1b1743100",
   "metadata": {},
   "source": [
    "# Text-based search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d442577-dbe9-405b-ab9a-dd93c9778f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qtxt = \"fast car\"\n",
    "\n",
    "query_bm25 = {\n",
    "  'size': 5,\n",
    "  '_source': ['caption', 'video_id', 'start', 'end', 'video_url'],\n",
    "  'query': {\n",
    "    'multi_match': {\n",
    "      'query': qtxt,\n",
    "      'fields': ['caption']\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "response = client.search(\n",
    "    body=query_bm25,\n",
    "    index=index_name\n",
    ")\n",
    "\n",
    "print('\\nSearch results:')\n",
    "for hit in response['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    print(f\"- {source['caption']} (video: {source['video_id']}, time: {source['start']}s → {source['end']}s)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1bc40d-4ae1-441a-9440-38e905cb3ff8",
   "metadata": {},
   "source": [
    "## Term-based search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0538f7-0903-443c-8f2e-931029cca7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_bm25 = {\n",
    "  'size':10,\n",
    "  '_source': ['caption'],\n",
    "  'query': {\n",
    "        \"term\": {\n",
    "            \"video_id\" : 'v_06ofnvq2Hjs'\n",
    "        }\n",
    "   }\n",
    "}\n",
    "\n",
    "response = client.search(\n",
    "    body = query_bm25,\n",
    "    index = index_name\n",
    ")\n",
    "\n",
    "print('\\nSearch results:')\n",
    "for hit in response['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    print(f\"- {source['caption']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b65b1a8-c5b4-4687-9558-b92eee5c560c",
   "metadata": {},
   "source": [
    "## Bool-based search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56deb6ec-443f-40d6-bb8e-86f3d2204ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_bm25 = {\n",
    "  'size': 10,\n",
    "  '_source': ['caption'],\n",
    "  'query': {\n",
    "    'bool': {\n",
    "      'must': [\n",
    "        { 'term': { 'video_id': 'v_06ofnvq2Hjs' } }\n",
    "      ],\n",
    "      'should': [\n",
    "        { 'match': { 'caption': 'car' } }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "response = client.search(\n",
    "    body=query_bm25,\n",
    "    index=index_name\n",
    ")\n",
    "\n",
    "print('\\nSearch results:')\n",
    "for hit in response['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    print(f\"- {source['caption']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04641906",
   "metadata": {},
   "source": [
    "### 2.3 Embeddings Neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83d19c3",
   "metadata": {},
   "source": [
    "## Dense Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0f10dd-1e99-4f40-9117-97888b74cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index_body = {\n",
    "    \"settings\": {\n",
    "        \"index\": {\n",
    "            \"number_of_replicas\": 0,\n",
    "            \"number_of_shards\": 4,\n",
    "            \"refresh_interval\": \"-1\",\n",
    "            \"knn\": \"true\"\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"dynamic\": \"strict\",\n",
    "        \"properties\": {\n",
    "            \"video_id\": {\"type\": \"keyword\"},\n",
    "            \"start\": {\"type\": \"float\"},\n",
    "            \"end\": {\"type\": \"float\"},\n",
    "            \"duration\": {\"type\": \"float\"},\n",
    "            \"caption\": {\"type\": \"text\", \"analyzer\": \"standard\"},\n",
    "            \"video_url\": {\"type\": \"keyword\"},\n",
    "            \"caption_vec\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 768,\n",
    "                \"method\": {\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"engine\": \"nmslib\",\n",
    "                    \"space_type\": \"cosinesimil\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "if client.indices.exists(index=index_name):\n",
    "    print(f\"Index '{index_name}' already exists. Deleting it to apply new mappings and settings...\")\n",
    "    client.indices.delete(index=index_name)\n",
    "\n",
    "# Create the index with fresh mappings and settings\n",
    "response = client.indices.create(index=index_name, body=index_body)\n",
    "print(f\"\\nIndex '{index_name}' created successfully.\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe0dc5",
   "metadata": {},
   "source": [
    "## Dual-Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d569760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take average of all tokens\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "#Encode text\n",
    "def encode(texts):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input, return_dict=True)\n",
    "\n",
    "    # Perform pooling\n",
    "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    # Normalize embeddings\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-v2\")\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "doc_emb = encode(selected_df['caption'].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a60f26",
   "metadata": {},
   "source": [
    "## Indexing document embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (idx, row) in enumerate(selected_df.iterrows()):\n",
    "    moment = {\n",
    "        'video_id': row['video_id'],\n",
    "        'caption': row['caption'],\n",
    "        'start': row['start'],\n",
    "        'end': row['end'],\n",
    "        'duration': row['duration'],\n",
    "        'video_url': row['video_url'],\n",
    "        'caption_vec': doc_emb[i].numpy()\n",
    "    }\n",
    "\n",
    "    \n",
    "    response = client.index(index=index_name, id=f\"{row['video_id']}_{row['start']}\", body=moment)\n",
    "    print(response['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609bd4b1",
   "metadata": {},
   "source": [
    "## Embedding spaces search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d16aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the query embedding\n",
    "query = \"fast car\"\n",
    "query_emb = encode(query)\n",
    "\n",
    "query_denc = {\n",
    "  'size': 5,\n",
    "  '_source': ['caption'],\n",
    "   \"query\": {\n",
    "        \"knn\": {\n",
    "          \"caption_vec\": {\n",
    "            \"vector\": query_emb[0].numpy(),\n",
    "            \"k\": 2\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "}\n",
    "\n",
    "response = client.search(\n",
    "    body = query_denc,\n",
    "    index = index_name\n",
    ")\n",
    "\n",
    "print('\\nSearch results:')\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addddf3d",
   "metadata": {},
   "source": [
    "## Search with boolean filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69349c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many moments have the captions about cars?\"\n",
    "query_emb = encode(query)\n",
    "\n",
    "query_bm25 = {\n",
    "  'size': 5,\n",
    "  '_source': ['caption'],\n",
    "  'query': {\n",
    "    'bool': {\n",
    "      'must': [\n",
    "        {\n",
    "          \"knn\": {\n",
    "            \"caption_vec\": {\n",
    "              \"vector\": query_emb[0].tolist(),\n",
    "              \"k\": 5\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      ],\n",
    "      'should': [\n",
    "        { 'match': { 'caption': 'car' } }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "response = client.search(\n",
    "    body = query_bm25,\n",
    "    index = index_name\n",
    ")\n",
    "\n",
    "print('\\nSearch results:')\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd13da",
   "metadata": {},
   "source": [
    "# 2.5 Contextual Embeddings and Self-Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcae80cd",
   "metadata": {},
   "source": [
    "## Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c664ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "from bertviz import model_view, head_view\n",
    "\n",
    "# Get the interactive Tools for Matplotlib\n",
    "#%matplotlib notebook\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90591b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_html():\n",
    "  import IPython\n",
    "  display(IPython.core.display.HTML('''\n",
    "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "        <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              base: '/static/base',\n",
    "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min\",\n",
    "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "        '''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a25e5f",
   "metadata": {},
   "source": [
    "## Bidirectional Encoder Representations Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35cb493",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'cross-encoder/ms-marco-MiniLM-L-12-v2'\n",
    "model_path = 'nboost/pt-bert-base-uncased-msmarco'\n",
    "CLS_token = \"[CLS]\"\n",
    "SEP_token = \"[SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aa1a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.logging.set_verbosity_warning()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "config = AutoConfig.from_pretrained(model_path,  output_hidden_states=True, output_attentions=True)  \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be03a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cf37ba",
   "metadata": {},
   "source": [
    "## Next Sentence Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56aa9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many moments involve a car?\"\n",
    "captions = selected_df['caption'].astype(str).tolist()[:5]\n",
    "\n",
    "sentence_a = [query] * len(captions)\n",
    "sentence_b = captions \n",
    "#inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True, max_length = 512, padding=True, truncation = True)\n",
    "inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True, max_length = 512, padding=True, truncation = True)\n",
    "\n",
    "\n",
    "pprint.pprint(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe36e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(inputs[\"input_ids\"][0].tolist()))\n",
    "print(tokenizer.decode(inputs[\"input_ids\"][1].tolist()))\n",
    "print(tokenizer.decode(inputs[\"input_ids\"][2].tolist()))\n",
    "print(tokenizer.decode(inputs[\"input_ids\"][3].tolist()))\n",
    "print(tokenizer.decode(inputs[\"input_ids\"][4].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d5a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = inputs['input_ids']\n",
    "input_id_list = input_ids[1].tolist() # Batch index 1\n",
    "pprint.pprint(input_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c9bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens_list = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "pprint.pprint(input_tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e0658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs = tokenizer(sentence_a, sentence_b, return_offsets_mapping = True, return_tensors='pt', add_special_tokens=True, max_length = 512, padding=True, truncation = True)\n",
    "inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True, max_length = 512, padding=True, truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886c6e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13539502",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = \"\\n\".join(\"{} \\t {}\".format(x, y) for x, y in zip(input_id_list, input_tokens_list))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b051a256",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e7c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc08a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f31b4d2",
   "metadata": {},
   "source": [
    "## Hidden layer embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c12f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of layers embeddings\n",
    "len(outputs['hidden_states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The format is as follow:\n",
    "# outputs['hidden_states'][layer_m][0][token_n]\n",
    "layer_m = 12\n",
    "token_n = 1\n",
    "# Get all the embeddings of one layer:\n",
    "output_embeddings = outputs['hidden_states'][layer_m][0]\n",
    "output_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c19d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_throat = 2\n",
    "token_cancer = 3\n",
    "\n",
    "# Get the embedding of one particular token in one particular layer\n",
    "throat_output_embedding = outputs['hidden_states'][layer_m][0][token_throat]\n",
    "throat_output_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d910315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca23f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scatterplot(data, words):\n",
    "\n",
    "    if data.shape[1] == 2:\n",
    "        twodim = data\n",
    "    else:\n",
    "        pca = PCA()\n",
    "        pca.fit(output_embeddings.detach().numpy())\n",
    "        twodim = pca.transform(data)[:,:2]\n",
    "    \n",
    "    plt.style.use('default') # https://matplotlib.org/3.5.1/gallery/style_sheets/style_sheets_reference.html\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.text(x+0.05, y+0.05, word)\n",
    "\n",
    "    return\n",
    "\n",
    "display_scatterplot(output_embeddings.detach().numpy(), input_tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f6e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_word_idx(sent: str, word: str):\n",
    "    tmp_lst = re.split(r' |\\?|\\.',sentence_a)\n",
    "    return tmp_lst.index(word)\n",
    "\n",
    "def get_word_vector(inputs, outputs, idx, layer):\n",
    "    \"\"\"Get a word vector by averaging the embeddings of \n",
    "       all word occurrences of that word in the input\"\"\"\n",
    "\n",
    "    # get all token idxs that belong to the word of interest\n",
    "    token_ids_word = np.where(np.array(inputs.word_ids()) == idx)\n",
    "    print(inputs.word_ids())\n",
    "    word_tokens_output = outputs.hidden_states[layer][0][token_ids_word]\n",
    "    print(token_ids_word)\n",
    "    return word_tokens_output.mean(dim=0)\n",
    "\n",
    "# The code below converts the tokens into a space delimited string.\n",
    "# This will allow computing in which position of the BERT input sequence a given word is.\n",
    "sentence_a = tokenizer.decode(inputs[\"input_ids\"][0].tolist()).replace(\"[CLS] \", '').replace(\" [SEP]\", '')\n",
    "word = \"car\"\n",
    "idx = get_word_idx(sentence_a, word)\n",
    "print(idx)\n",
    "print(\"Input sequence:\", sentence_a)\n",
    "print(\"The word \\\"\", word, \"\\\" occurs in position\", idx, \"of the BERT input sequence.\")\n",
    "\n",
    "word_embedding = get_word_vector(inputs, outputs, idx, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40951d5",
   "metadata": {},
   "source": [
    "# Attention and Embeddings Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146cac60",
   "metadata": {},
   "source": [
    "## Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a4a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import logging\n",
    "logging.set_verbosity_warning()\n",
    "\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "from bertviz import model_view, head_view\n",
    "\n",
    "# Get the interactive Tools for Matplotlib\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd921d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_html():\n",
    "  import IPython\n",
    "  display(IPython.core.display.HTML('''\n",
    "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "        <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              base: '/static/base',\n",
    "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min\",\n",
    "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "        '''))\n",
    "    \n",
    "def display_scatterplot(model, words):\n",
    "\n",
    "    if model.shape[1] == 2:\n",
    "        twodim = model\n",
    "    else:\n",
    "        twodim = PCA().fit_transform(model)[:,:2]\n",
    "    \n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.text(x+0.05, y+0.05, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9c0c33",
   "metadata": {},
   "source": [
    "# Model Explainability with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b92250",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'deepset/roberta-base-squad2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc1595",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "config = AutoConfig.from_pretrained(model_path,  output_hidden_states=True, output_attentions=True)  \n",
    "model = AutoModel.from_pretrained(model_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98fb8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many moments involve a car?\"\n",
    "captions = selected_df['caption'].astype(str).tolist()[:1]\n",
    "\n",
    "sentence_a = [query] * len(captions)\n",
    "sentence_b = captions \n",
    "inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True, max_length = 512, truncation = True, padding=True)\n",
    "\n",
    "input_ids = inputs['input_ids']\n",
    "input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54693d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, output_attentions=True)\n",
    "\n",
    "attention = outputs.attentions\n",
    "hidden_states = outputs.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc1c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rows = 3\n",
    "cols = 4\n",
    "fig, ax_full = plt.subplots(rows, cols)\n",
    "fig.set_figheight(rows*4)\n",
    "fig.set_figwidth(cols*4+3)\n",
    "plt.rcParams.update({'font.size': 6})\n",
    "\n",
    "\n",
    "layer = 0\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "       \n",
    "        ax = ax_full[r,c]\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 10})\n",
    "        current_hidden_state = hidden_states[layer][0].detach().numpy()\n",
    "        \n",
    "        if current_hidden_state.shape[1] == 2:\n",
    "            twodim = current_hidden_state\n",
    "        else:\n",
    "            twodim = PCA().fit_transform(current_hidden_state)[:,:2]\n",
    "\n",
    "        plt.style.use('default') # https://matplotlib.org/3.5.1/gallery/style_sheets/style_sheets_reference.html\n",
    "        im = ax.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "        for word, (x,y) in zip(tokens, twodim):\n",
    "            ax.text(x+0.05, y+0.05, word[1:])\n",
    "        \n",
    "        # Show all ticks and label them with the respective list entries\n",
    "        ax.set_title(\"Layer \" + str(layer))\n",
    "            \n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        layer = layer + 1\n",
    "\n",
    "fig.suptitle(\"Visualization of all output embeddings from all layers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2a7cae",
   "metadata": {},
   "source": [
    "## Token specific visualzation of self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a4015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then visualize\n",
    "call_html()\n",
    "head_view(attention, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfd779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "layer = 1\n",
    "\n",
    "rows = 3\n",
    "cols = 4\n",
    "fig, ax_full = plt.subplots(rows, cols)\n",
    "fig.set_figheight(rows*6)\n",
    "fig.set_figwidth(cols*6+4)\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "j = 0\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "       \n",
    "        ax = ax_full[r,c]\n",
    "        \n",
    "        sattention = attention[layer][0][j].numpy()\n",
    "        sattention = np.flip(sattention, 0)\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "        im = ax.pcolormesh(sattention, cmap='gnuplot')\n",
    "\n",
    "        # Show all ticks and label them with the respective list entries\n",
    "        ax.set_title(\"Head \" + str(j))\n",
    "        ax.set_yticks(np.arange(len(tokens)))\n",
    "        if c == 0:\n",
    "            ax.set_yticklabels(reversed(tokens))\n",
    "            ax.set_ylabel(\"Queries\")\n",
    "        else:\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        ax.set_xticks(np.arange(len(tokens)))\n",
    "        if r == rows-1:\n",
    "            ax.set_xticklabels(tokens)\n",
    "            ax.set_xlabel(\"Keys\")\n",
    "            \n",
    "            # Rotate the tick labels and set their alignment.\n",
    "            plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                     rotation_mode=\"anchor\")\n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "\n",
    "            \n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        j = j + 1\n",
    "\n",
    "fig.suptitle(\"Layer\" + str(layer) + \" Multi-head Self-attentions\")\n",
    "cbar = fig.colorbar(im, ax=ax_full, location='right', shrink=0.5)\n",
    "cbar.ax.set_ylabel(\"Selt-attention\", rotation=-90, va=\"bottom\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5047ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_view(attention, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e566586a",
   "metadata": {},
   "source": [
    "## Positional Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb6755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'deepset/roberta-base-squad2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233045f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "config = AutoConfig.from_pretrained(model_path,  output_hidden_states=True, output_attentions=True)  \n",
    "model = AutoModel.from_pretrained(model_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6907a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"car\"\n",
    "sentence = \" \".join([word] * 20)\n",
    "\n",
    "captions = selected_df['caption'].astype(str).tolist()[:1]\n",
    "\n",
    "sentence_a = [sentence] * len(captions)\n",
    "sentence_b = captions \n",
    "inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True, max_length = 512, truncation = True, padding=True)\n",
    "\n",
    "input_ids = inputs['input_ids']\n",
    "input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a2b21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, output_attentions=True)\n",
    "\n",
    "attention = outputs.attentions\n",
    "hidden_states = outputs.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967deeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rows = 3\n",
    "cols = 4\n",
    "fig, ax_full = plt.subplots(rows, cols)\n",
    "fig.set_figheight(rows*4)\n",
    "fig.set_figwidth(cols*4+3)\n",
    "plt.rcParams.update({'font.size': 6})\n",
    "\n",
    "layer = 0\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "       \n",
    "        ax = ax_full[r,c]\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 10})\n",
    "        current_hidden_state = hidden_states[layer][0].detach().numpy()\n",
    "        \n",
    "        if current_hidden_state.shape[1] == 2:\n",
    "            twodim = current_hidden_state\n",
    "        else:\n",
    "            twodim = PCA().fit_transform(current_hidden_state)[:,:2]\n",
    "\n",
    "        plt.style.use('default') # https://matplotlib.org/3.5.1/gallery/style_sheets/style_sheets_reference.html\n",
    "        im = ax.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "        for word, (x,y) in zip(tokens, twodim):\n",
    "            ax.text(x+0.05, y+0.05, word[1:])\n",
    "        \n",
    "        # Show all ticks and label them with the respective list entries\n",
    "        ax.set_title(\"Layer \" + str(layer))\n",
    "            \n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        layer = layer + 1\n",
    "\n",
    "fig.suptitle(\"Visualization of all output embeddings from all layers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f4ed0",
   "metadata": {},
   "source": [
    "## Dual Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8639db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547a6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "config = AutoConfig.from_pretrained(model_path,  output_hidden_states=True, output_attentions=True)  \n",
    "model = AutoModel.from_pretrained(model_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e18027",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = selected_df['caption'].astype(str).tolist()[:1]\n",
    "\n",
    "inputs = tokenizer(captions, return_tensors='pt', truncation=True, padding=True)\n",
    "\n",
    "input_ids = inputs['input_ids']\n",
    "input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, output_attentions=True)\n",
    "\n",
    "attention = outputs.attentions\n",
    "hidden_states = outputs.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9730bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rows = 3\n",
    "cols = 4\n",
    "fig, ax_full = plt.subplots(rows, cols)\n",
    "fig.set_figheight(rows*4)\n",
    "fig.set_figwidth(cols*4+3)\n",
    "plt.rcParams.update({'font.size': 6})\n",
    "\n",
    "layer = 0\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "       \n",
    "        ax = ax_full[r,c]\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 10})\n",
    "        current_hidden_state = hidden_states[layer][0].detach().numpy()\n",
    "        \n",
    "        if current_hidden_state.shape[1] == 2:\n",
    "            twodim = current_hidden_state\n",
    "        else:\n",
    "            twodim = PCA().fit_transform(current_hidden_state)[:,:2]\n",
    "\n",
    "        plt.style.use('default') # https://matplotlib.org/3.5.1/gallery/style_sheets/style_sheets_reference.html\n",
    "        im = ax.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "        for word, (x,y) in zip(tokens, twodim):\n",
    "            ax.text(x+0.05, y+0.05, word)\n",
    "        \n",
    "        # Show all ticks and label them with the respective list entries\n",
    "        ax.set_title(\"Layer \" + str(layer))\n",
    "            \n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        layer = layer + 1\n",
    "\n",
    "fig.suptitle(\"Visualization of all output embeddings from all layers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then visualize\n",
    "call_html()\n",
    "head_view(attention, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1714932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "layer = 1\n",
    "\n",
    "rows = 3\n",
    "cols = 4\n",
    "fig, ax_full = plt.subplots(rows, cols)\n",
    "fig.set_figheight(rows*6)\n",
    "fig.set_figwidth(cols*6+4)\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "j = 0\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "       \n",
    "        ax = ax_full[r,c]\n",
    "        \n",
    "        sattention = attention[layer][0][j].numpy()\n",
    "        sattention = np.flip(sattention, 0)\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "        im = ax.pcolormesh(sattention, cmap='gnuplot')\n",
    "\n",
    "        # Show all ticks and label them with the respective list entries\n",
    "        ax.set_title(\"Head \" + str(j))\n",
    "        ax.set_yticks(np.arange(len(tokens)))\n",
    "        if c == 0:\n",
    "            ax.set_yticklabels(reversed(tokens))\n",
    "            ax.set_ylabel(\"Queries\")\n",
    "        else:\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        ax.set_xticks(np.arange(len(tokens)))\n",
    "        if r == rows-1:\n",
    "            ax.set_xticklabels(tokens)\n",
    "            ax.set_xlabel(\"Keys\")\n",
    "            \n",
    "            # Rotate the tick labels and set their alignment.\n",
    "            plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                     rotation_mode=\"anchor\")\n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "\n",
    "            \n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        j = j + 1\n",
    "\n",
    "fig.suptitle(\"Layer\" + str(layer) + \" Multi-head Self-attentions\")\n",
    "cbar = fig.colorbar(im, ax=ax_full, location='right', shrink=0.5)\n",
    "cbar.ax.set_ylabel(\"Selt-attention\", rotation=-90, va=\"bottom\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3dba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_view(attention, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1194456",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many moments involve a car?\"\n",
    "inputs = tokenizer(query, return_tensors='pt', truncation=True, padding=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "attention = outputs.attentions\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "\n",
    "head_view(attention, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdf0737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "layer = 1\n",
    "\n",
    "rows = 3\n",
    "cols = 4\n",
    "fig, ax_full = plt.subplots(rows, cols)\n",
    "fig.set_figheight(rows*6)\n",
    "fig.set_figwidth(cols*6+4)\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "j = 0\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "       \n",
    "        ax = ax_full[r,c]\n",
    "        \n",
    "        sattention = attention[layer][0][j].numpy()\n",
    "        sattention = np.flip(sattention, 0)\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "        im = ax.pcolormesh(sattention, cmap='gnuplot')\n",
    "\n",
    "        # Show all ticks and label them with the respective list entries\n",
    "        ax.set_title(\"Head \" + str(j))\n",
    "        ax.set_yticks(np.arange(len(tokens)))\n",
    "        if c == 0:\n",
    "            ax.set_yticklabels(reversed(tokens))\n",
    "            ax.set_ylabel(\"Queries\")\n",
    "        else:\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        ax.set_xticks(np.arange(len(tokens)))\n",
    "        if r == rows-1:\n",
    "            ax.set_xticklabels(tokens)\n",
    "            ax.set_xlabel(\"Keys\")\n",
    "            \n",
    "            # Rotate the tick labels and set their alignment.\n",
    "            plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                     rotation_mode=\"anchor\")\n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "\n",
    "            \n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        j = j + 1\n",
    "\n",
    "fig.suptitle(\"Layer\" + str(layer) + \" Multi-head Self-attentions\")\n",
    "cbar = fig.colorbar(im, ax=ax_full, location='right', shrink=0.5)\n",
    "cbar.ax.set_ylabel(\"Selt-attention\", rotation=-90, va=\"bottom\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c450fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_view(attention, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c001ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-cv-ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
