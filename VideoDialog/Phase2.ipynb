{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c31b05",
   "metadata": {},
   "source": [
    "# Phase2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02289b93",
   "metadata": {},
   "source": [
    "# Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba621c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pprint as pp\n",
    "import requests\n",
    "\n",
    "host = 'api.novasearch.org'\n",
    "port = 443\n",
    "\n",
    "user = 'user02' # Add your user name here.\n",
    "password = 'marco.2025+' # Add your user password here. For testing only. Don't store credentials in code. \n",
    "index_name = user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1348fa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: HTTPConnectionPool(host='localhost', port=9200): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000024ED1764970>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings()  # Suppress self-signed cert warnings\n",
    "\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import requests\n",
    "import pprint as pp\n",
    "\n",
    "host = 'localhost'\n",
    "port = 9200\n",
    "user = 'admin'\n",
    "password = 'MyStr0ng@Pass'\n",
    "index_name = user\n",
    "\n",
    "url = f\"http://{host}:{port}\"\n",
    "\n",
    "try:\n",
    "    res = requests.get(url, auth=HTTPBasicAuth(user, password), verify=False)\n",
    "    pp.pprint(res.json())\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Request failed:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0ce917",
   "metadata": {},
   "source": [
    "# Frame Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42f3893f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading captions from: C:\\Users\\nunoj\\Desktop\\MPWD\\Project\\VideoDialog\\captions\\train.json\n",
      "Found 12 potentially valid video IDs based on caption criteria.\n",
      "\n",
      "Starting download and frame extraction (every 2.0s), aiming for 10 successful videos...\n",
      "\n",
      "Attempting to process video 1/12 (target 1/10): v_MWdPh6J-YXM from https://www.youtube.com/watch?v=MWdPh6J-YXM\n",
      "Downloading video: v_MWdPh6J-YXM using yt-dlp...\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=MWdPh6J-YXM\n",
      "[youtube] MWdPh6J-YXM: Downloading webpage\n",
      "[youtube] MWdPh6J-YXM: Downloading tv client config\n",
      "[youtube] MWdPh6J-YXM: Downloading tv player API JSON\n",
      "[youtube] MWdPh6J-YXM: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] MWdPh6J-YXM: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping v_MWdPh6J-YXM: Video is private (yt-dlp).\n",
      "\n",
      "Attempting to process video 2/12 (target 1/10): v_1LdbczjQPII from https://www.youtube.com/watch?v=1LdbczjQPII\n",
      "Downloading video: v_1LdbczjQPII using yt-dlp...\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=1LdbczjQPII\n",
      "[youtube] 1LdbczjQPII: Downloading webpage\n",
      "[youtube] 1LdbczjQPII: Downloading tv client config\n",
      "[youtube] 1LdbczjQPII: Downloading tv player API JSON\n",
      "[youtube] 1LdbczjQPII: Downloading ios player API JSON\n",
      "[youtube] 1LdbczjQPII: Downloading m3u8 information\n",
      "[info] 1LdbczjQPII: Downloading 1 format(s): 136+140\n",
      "[download] Destination: extracted_frames\\temp_videos\\v_1LdbczjQPII.f136.mp4\n",
      "[download] 100% of   20.39MiB in 00:00:12 at 1.66MiB/s     \n",
      "[download] Destination: extracted_frames\\temp_videos\\v_1LdbczjQPII.f140.m4a\n",
      "[download] 100% of    2.52MiB in 00:00:01 at 1.49MiB/s   \n",
      "[Merger] Merging formats into \"extracted_frames\\temp_videos\\v_1LdbczjQPII.mp4\"\n",
      "Deleting original file extracted_frames\\temp_videos\\v_1LdbczjQPII.f140.m4a (pass -k to keep)\n",
      "Deleting original file extracted_frames\\temp_videos\\v_1LdbczjQPII.f136.mp4 (pass -k to keep)\n",
      "Downloaded to extracted_frames\\temp_videos\\v_1LdbczjQPII.mp4\n",
      "Extracting frames for v_1LdbczjQPII at ~2.0s intervals...\n",
      "  Video FPS: 29.97, Extracting 1 frame every 60 frames.\n",
      "82 frames saved for v_1LdbczjQPII in extracted_frames\\v_1LdbczjQPII\n",
      "Cleaning up video file: extracted_frames\\temp_videos\\v_1LdbczjQPII.mp4\n",
      "\n",
      "Attempting to process video 3/12 (target 2/10): v_uICwWvS_AOo from https://www.youtube.com/watch?v=uICwWvS_AOo\n",
      "Downloading video: v_uICwWvS_AOo using yt-dlp...\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=uICwWvS_AOo\n",
      "[youtube] uICwWvS_AOo: Downloading webpage\n",
      "[youtube] uICwWvS_AOo: Downloading tv client config\n",
      "[youtube] uICwWvS_AOo: Downloading tv player API JSON\n",
      "[youtube] uICwWvS_AOo: Downloading ios player API JSON\n",
      "[youtube] uICwWvS_AOo: Downloading m3u8 information\n",
      "[info] uICwWvS_AOo: Downloading 1 format(s): 135+140\n",
      "[download] Destination: extracted_frames\\temp_videos\\v_uICwWvS_AOo.f135.mp4\n",
      "[download] 100% of   19.07MiB in 00:00:11 at 1.72MiB/s     \n",
      "[download] Destination: extracted_frames\\temp_videos\\v_uICwWvS_AOo.f140.m4a\n",
      "[download] 100% of    2.22MiB in 00:00:01 at 1.58MiB/s   \n",
      "[Merger] Merging formats into \"extracted_frames\\temp_videos\\v_uICwWvS_AOo.mp4\"\n",
      "Deleting original file extracted_frames\\temp_videos\\v_uICwWvS_AOo.f140.m4a (pass -k to keep)\n",
      "Deleting original file extracted_frames\\temp_videos\\v_uICwWvS_AOo.f135.mp4 (pass -k to keep)\n",
      "Downloaded to extracted_frames\\temp_videos\\v_uICwWvS_AOo.mp4\n",
      "Extracting frames for v_uICwWvS_AOo at ~2.0s intervals...\n",
      "  Video FPS: 25.00, Extracting 1 frame every 50 frames.\n",
      "96 frames saved for v_uICwWvS_AOo in extracted_frames\\v_uICwWvS_AOo\n",
      "Cleaning up video file: extracted_frames\\temp_videos\\v_uICwWvS_AOo.mp4\n",
      "\n",
      "Attempting to process video 4/12 (target 3/10): v_Gms3Yt6RrV4 from https://www.youtube.com/watch?v=Gms3Yt6RrV4\n",
      "Downloading video: v_Gms3Yt6RrV4 using yt-dlp...\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=Gms3Yt6RrV4\n",
      "[youtube] Gms3Yt6RrV4: Downloading webpage\n",
      "[youtube] Gms3Yt6RrV4: Downloading tv client config\n",
      "[youtube] Gms3Yt6RrV4: Downloading tv player API JSON\n",
      "[youtube] Gms3Yt6RrV4: Downloading ios player API JSON\n",
      "[youtube] Gms3Yt6RrV4: Downloading m3u8 information\n",
      "[info] Gms3Yt6RrV4: Downloading 1 format(s): 134+140\n",
      "[download] Destination: extracted_frames\\temp_videos\\v_Gms3Yt6RrV4.f134.mp4\n",
      "[download] 100% of    3.39MiB in 00:00:01 at 1.73MiB/s     \n",
      "[download] Destination: extracted_frames\\temp_videos\\v_Gms3Yt6RrV4.f140.m4a\n",
      "[download] 100% of    2.30MiB in 00:00:01 at 1.44MiB/s   \n",
      "[Merger] Merging formats into \"extracted_frames\\temp_videos\\v_Gms3Yt6RrV4.mp4\"\n",
      "Deleting original file extracted_frames\\temp_videos\\v_Gms3Yt6RrV4.f134.mp4 (pass -k to keep)\n",
      "Deleting original file extracted_frames\\temp_videos\\v_Gms3Yt6RrV4.f140.m4a (pass -k to keep)\n",
      "Downloaded to extracted_frames\\temp_videos\\v_Gms3Yt6RrV4.mp4\n",
      "Extracting frames for v_Gms3Yt6RrV4 at ~2.0s intervals...\n",
      "  Video FPS: 30.00, Extracting 1 frame every 60 frames.\n",
      "75 frames saved for v_Gms3Yt6RrV4 in extracted_frames\\v_Gms3Yt6RrV4\n",
      "Cleaning up video file: extracted_frames\\temp_videos\\v_Gms3Yt6RrV4.mp4\n",
      "\n",
      "Attempting to process video 5/12 (target 4/10): v_amCD-2TIKw0 from https://www.youtube.com/watch?v=amCD-2TIKw0\n",
      "Downloading video: v_amCD-2TIKw0 using yt-dlp...\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=amCD-2TIKw0\n",
      "[youtube] amCD-2TIKw0: Downloading webpage\n",
      "[youtube] amCD-2TIKw0: Downloading tv client config\n",
      "[youtube] amCD-2TIKw0: Downloading tv player API JSON\n",
      "[youtube] amCD-2TIKw0: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] amCD-2TIKw0: Video unavailable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping v_amCD-2TIKw0: Video is unavailable (yt-dlp).\n",
      "\n",
      "Attempting to process video 6/12 (target 4/10): v_jPLJAYnjsBw from https://www.youtube.com/watch?v=jPLJAYnjsBw\n",
      "Downloading video: v_jPLJAYnjsBw using yt-dlp...\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=jPLJAYnjsBw\n",
      "[youtube] jPLJAYnjsBw: Downloading webpage\n",
      "[youtube] jPLJAYnjsBw: Downloading tv client config\n",
      "[youtube] jPLJAYnjsBw: Downloading tv player API JSON\n",
      "[youtube] jPLJAYnjsBw: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] jPLJAYnjsBw: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping v_jPLJAYnjsBw: Video is private (yt-dlp).\n",
      "\n",
      "Attempting to process video 7/12 (target 4/10): v_Eilil6FZhK8 from https://www.youtube.com/watch?v=Eilil6FZhK8\n",
      "Downloading video: v_Eilil6FZhK8 using yt-dlp...\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=Eilil6FZhK8\n",
      "[youtube] Eilil6FZhK8: Downloading webpage\n",
      "[youtube] Eilil6FZhK8: Downloading tv client config\n",
      "[youtube] Eilil6FZhK8: Downloading tv player API JSON\n",
      "[youtube] Eilil6FZhK8: Downloading ios player API JSON\n",
      "[youtube] Eilil6FZhK8: Downloading m3u8 information\n",
      "[info] Eilil6FZhK8: Downloading 1 format(s): 134+140\n",
      "[download] Destination: extracted_frames\\temp_videos\\v_Eilil6FZhK8.f134.mp4\n",
      "[download] 100% of    7.28MiB in 00:00:04 at 1.75MiB/s   \n",
      "[download] Destination: extracted_frames\\temp_videos\\v_Eilil6FZhK8.f140.m4a\n",
      "[download] 100% of    3.38MiB in 00:00:02 at 1.64MiB/s   \n",
      "[Merger] Merging formats into \"extracted_frames\\temp_videos\\v_Eilil6FZhK8.mp4\"\n",
      "Deleting original file extracted_frames\\temp_videos\\v_Eilil6FZhK8.f134.mp4 (pass -k to keep)\n",
      "Deleting original file extracted_frames\\temp_videos\\v_Eilil6FZhK8.f140.m4a (pass -k to keep)\n",
      "Downloaded to extracted_frames\\temp_videos\\v_Eilil6FZhK8.mp4\n",
      "Extracting frames for v_Eilil6FZhK8 at ~2.0s intervals...\n",
      "  Video FPS: 25.00, Extracting 1 frame every 50 frames.\n",
      "110 frames saved for v_Eilil6FZhK8 in extracted_frames\\v_Eilil6FZhK8\n",
      "Cleaning up video file: extracted_frames\\temp_videos\\v_Eilil6FZhK8.mp4\n",
      "\n",
      "Attempting to process video 8/12 (target 5/10): v_9DVsv84awMg from https://www.youtube.com/watch?v=9DVsv84awMg\n",
      "Downloading video: v_9DVsv84awMg using yt-dlp...\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=9DVsv84awMg\n",
      "[youtube] 9DVsv84awMg: Downloading webpage\n",
      "[youtube] 9DVsv84awMg: Downloading tv client config\n",
      "[youtube] 9DVsv84awMg: Downloading tv player API JSON\n",
      "[youtube] 9DVsv84awMg: Downloading ios player API JSON\n",
      "[youtube] 9DVsv84awMg: Downloading m3u8 information\n",
      "[info] 9DVsv84awMg: Downloading 1 format(s): 136+140\n",
      "[download] Destination: extracted_frames\\temp_videos\\v_9DVsv84awMg.f136.mp4\n",
      "[download] 100% of   40.57MiB in 00:00:24 at 1.67MiB/s   \n",
      "[download] Destination: extracted_frames\\temp_videos\\v_9DVsv84awMg.f140.m4a\n",
      "[download] 100% of    3.30MiB in 00:00:02 at 1.56MiB/s     \n",
      "[Merger] Merging formats into \"extracted_frames\\temp_videos\\v_9DVsv84awMg.mp4\"\n",
      "Deleting original file extracted_frames\\temp_videos\\v_9DVsv84awMg.f140.m4a (pass -k to keep)\n",
      "Deleting original file extracted_frames\\temp_videos\\v_9DVsv84awMg.f136.mp4 (pass -k to keep)\n",
      "Downloaded to extracted_frames\\temp_videos\\v_9DVsv84awMg.mp4\n",
      "Extracting frames for v_9DVsv84awMg at ~2.0s intervals...\n",
      "  Video FPS: 25.00, Extracting 1 frame every 50 frames.\n",
      "107 frames saved for v_9DVsv84awMg in extracted_frames\\v_9DVsv84awMg\n",
      "Cleaning up video file: extracted_frames\\temp_videos\\v_9DVsv84awMg.mp4\n",
      "\n",
      "Attempting to process video 9/12 (target 6/10): v_9hR1MHvXGv8 from https://www.youtube.com/watch?v=9hR1MHvXGv8\n",
      "Downloading video: v_9hR1MHvXGv8 using yt-dlp...\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=9hR1MHvXGv8\n",
      "[youtube] 9hR1MHvXGv8: Downloading webpage\n",
      "[youtube] 9hR1MHvXGv8: Downloading tv client config\n",
      "[youtube] 9hR1MHvXGv8: Downloading tv player API JSON\n",
      "[youtube] 9hR1MHvXGv8: Downloading ios player API JSON\n",
      "[youtube] 9hR1MHvXGv8: Downloading m3u8 information\n",
      "[info] 9hR1MHvXGv8: Downloading 1 format(s): 137+140\n",
      "[download] Destination: extracted_frames\\temp_videos\\v_9hR1MHvXGv8.f137.mp4\n",
      "[download] 100% of   39.33MiB in 00:00:23 at 1.69MiB/s     \n",
      "[download] Destination: extracted_frames\\temp_videos\\v_9hR1MHvXGv8.f140.m4a\n",
      "[download] 100% of    1.74MiB in 00:00:01 at 1.45MiB/s   \n",
      "[Merger] Merging formats into \"extracted_frames\\temp_videos\\v_9hR1MHvXGv8.mp4\"\n",
      "Deleting original file extracted_frames\\temp_videos\\v_9hR1MHvXGv8.f140.m4a (pass -k to keep)\n",
      "Deleting original file extracted_frames\\temp_videos\\v_9hR1MHvXGv8.f137.mp4 (pass -k to keep)\n",
      "Downloaded to extracted_frames\\temp_videos\\v_9hR1MHvXGv8.mp4\n",
      "Extracting frames for v_9hR1MHvXGv8 at ~2.0s intervals...\n",
      "  Video FPS: 29.97, Extracting 1 frame every 60 frames.\n",
      "57 frames saved for v_9hR1MHvXGv8 in extracted_frames\\v_9hR1MHvXGv8\n",
      "Cleaning up video file: extracted_frames\\temp_videos\\v_9hR1MHvXGv8.mp4\n",
      "\n",
      "Attempting to process video 10/12 (target 7/10): v_S5kuckj4Ud4 from https://www.youtube.com/watch?v=S5kuckj4Ud4\n",
      "Downloading video: v_S5kuckj4Ud4 using yt-dlp...\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=S5kuckj4Ud4\n",
      "[youtube] S5kuckj4Ud4: Downloading webpage\n",
      "[youtube] S5kuckj4Ud4: Downloading tv client config\n",
      "[youtube] S5kuckj4Ud4: Downloading tv player API JSON\n",
      "[youtube] S5kuckj4Ud4: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] S5kuckj4Ud4: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping v_S5kuckj4Ud4: Video is private (yt-dlp).\n",
      "\n",
      "Attempting to process video 11/12 (target 7/10): v_9V7cMp_w1_0 from https://www.youtube.com/watch?v=9V7cMp_w1_0\n",
      "Downloading video: v_9V7cMp_w1_0 using yt-dlp...\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=9V7cMp_w1_0\n",
      "[youtube] 9V7cMp_w1_0: Downloading webpage\n",
      "[youtube] 9V7cMp_w1_0: Downloading tv client config\n",
      "[youtube] 9V7cMp_w1_0: Downloading tv player API JSON\n",
      "[youtube] 9V7cMp_w1_0: Downloading ios player API JSON\n",
      "[youtube] 9V7cMp_w1_0: Downloading m3u8 information\n",
      "[info] 9V7cMp_w1_0: Downloading 1 format(s): 605+140\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 35\n",
      "[download] Destination: extracted_frames\\temp_videos\\v_9V7cMp_w1_0.f605.mp4\n",
      "[download] 100% of    4.42MiB in 00:00:06 at 697.83KiB/s                \n",
      "[download] Destination: extracted_frames\\temp_videos\\v_9V7cMp_w1_0.f140.m4a\n",
      "[download] 100% of    2.73MiB in 00:00:02 at 1.30MiB/s   \n",
      "[Merger] Merging formats into \"extracted_frames\\temp_videos\\v_9V7cMp_w1_0.mp4\"\n",
      "Deleting original file extracted_frames\\temp_videos\\v_9V7cMp_w1_0.f140.m4a (pass -k to keep)\n",
      "Deleting original file extracted_frames\\temp_videos\\v_9V7cMp_w1_0.f605.mp4 (pass -k to keep)\n",
      "Downloaded to extracted_frames\\temp_videos\\v_9V7cMp_w1_0.mp4\n",
      "Extracting frames for v_9V7cMp_w1_0 at ~2.0s intervals...\n",
      "  Video FPS: 25.00, Extracting 1 frame every 50 frames.\n",
      "89 frames saved for v_9V7cMp_w1_0 in extracted_frames\\v_9V7cMp_w1_0\n",
      "Cleaning up video file: extracted_frames\\temp_videos\\v_9V7cMp_w1_0.mp4\n",
      "\n",
      "Attempting to process video 12/12 (target 8/10): v_06ofnvq2Hjs from https://www.youtube.com/watch?v=06ofnvq2Hjs\n",
      "Downloading video: v_06ofnvq2Hjs using yt-dlp...\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=06ofnvq2Hjs\n",
      "[youtube] 06ofnvq2Hjs: Downloading webpage\n",
      "[youtube] 06ofnvq2Hjs: Downloading tv client config\n",
      "[youtube] 06ofnvq2Hjs: Downloading tv player API JSON\n",
      "[youtube] 06ofnvq2Hjs: Downloading ios player API JSON\n",
      "[youtube] 06ofnvq2Hjs: Downloading m3u8 information\n",
      "[info] 06ofnvq2Hjs: Downloading 1 format(s): 136+140\n",
      "[download] Destination: extracted_frames\\temp_videos\\v_06ofnvq2Hjs.f136.mp4\n",
      "[download] 100% of   49.86MiB in 00:00:33 at 1.48MiB/s     \n",
      "[download] Destination: extracted_frames\\temp_videos\\v_06ofnvq2Hjs.f140.m4a\n",
      "[download] 100% of    3.14MiB in 00:00:02 at 1.49MiB/s   \n",
      "[Merger] Merging formats into \"extracted_frames\\temp_videos\\v_06ofnvq2Hjs.mp4\"\n",
      "Deleting original file extracted_frames\\temp_videos\\v_06ofnvq2Hjs.f136.mp4 (pass -k to keep)\n",
      "Deleting original file extracted_frames\\temp_videos\\v_06ofnvq2Hjs.f140.m4a (pass -k to keep)\n",
      "Downloaded to extracted_frames\\temp_videos\\v_06ofnvq2Hjs.mp4\n",
      "Extracting frames for v_06ofnvq2Hjs at ~2.0s intervals...\n",
      "  Video FPS: 29.97, Extracting 1 frame every 60 frames.\n",
      "102 frames saved for v_06ofnvq2Hjs in extracted_frames\\v_06ofnvq2Hjs\n",
      "Cleaning up video file: extracted_frames\\temp_videos\\v_06ofnvq2Hjs.mp4\n",
      "\n",
      "Finished processing loop.\n",
      "8 videos had frames successfully extracted.\n",
      "Could not reach the target of 10 videos. Attempted 12 out of 12 potential videos.\n",
      "\n",
      "Summary of successfully processed videos and extracted frames:\n",
      "  Video ID: v_1LdbczjQPII, Frames Extracted: 82, Path: extracted_frames\\v_1LdbczjQPII\n",
      "  Video ID: v_uICwWvS_AOo, Frames Extracted: 96, Path: extracted_frames\\v_uICwWvS_AOo\n",
      "  Video ID: v_Gms3Yt6RrV4, Frames Extracted: 75, Path: extracted_frames\\v_Gms3Yt6RrV4\n",
      "  Video ID: v_Eilil6FZhK8, Frames Extracted: 110, Path: extracted_frames\\v_Eilil6FZhK8\n",
      "  Video ID: v_9DVsv84awMg, Frames Extracted: 107, Path: extracted_frames\\v_9DVsv84awMg\n",
      "  Video ID: v_9hR1MHvXGv8, Frames Extracted: 57, Path: extracted_frames\\v_9hR1MHvXGv8\n",
      "  Video ID: v_9V7cMp_w1_0, Frames Extracted: 89, Path: extracted_frames\\v_9V7cMp_w1_0\n",
      "  Video ID: v_06ofnvq2Hjs, Frames Extracted: 102, Path: extracted_frames\\v_06ofnvq2Hjs\n",
      "Total frames extracted across all successful videos: 718\n",
      "\n",
      "Selected 84 captions from the 8 videos that had frames extracted:\n",
      "video_id\n",
      "v_06ofnvq2Hjs    10\n",
      "v_1LdbczjQPII    14\n",
      "v_9DVsv84awMg    13\n",
      "v_9V7cMp_w1_0    10\n",
      "v_9hR1MHvXGv8    10\n",
      "v_Eilil6FZhK8     9\n",
      "v_Gms3Yt6RrV4     9\n",
      "v_uICwWvS_AOo     9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import yt_dlp\n",
    "import av # For frame extraction\n",
    "import os\n",
    "import time\n",
    "import math # For ceiling function if needed for frame counts\n",
    "\n",
    "# --- Provided load_captions function (remains the same) ---\n",
    "def load_captions(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    result = []\n",
    "    for vid_key, meta_info in data.items():\n",
    "        if isinstance(meta_info, dict) and 'timestamps' in meta_info and 'sentences' in meta_info:\n",
    "            for (start, end), sentence in zip(meta_info['timestamps'], meta_info['sentences']):\n",
    "                result.append({\n",
    "                    \"video_id\": vid_key,\n",
    "                    \"duration\": meta_info.get(\"duration\", 0),\n",
    "                    \"start\": start,\n",
    "                    \"end\": end,\n",
    "                    \"caption\": sentence,\n",
    "                    \"video_url\": f\"https://www.youtube.com/watch?v={vid_key[2:]}\" if vid_key.startswith(\"v_\") else f\"https://www.youtube.com/watch?v={vid_key}\"\n",
    "                })\n",
    "        else:\n",
    "            print(f\"Warning: Skipping entry {vid_key} in load_captions due to unexpected structure or missing keys.\")\n",
    "    return result\n",
    "\n",
    "# --- Setup ---\n",
    "repo_root = Path().resolve()\n",
    "json_path = repo_root / \"captions\" / \"train.json\"\n",
    "OUTPUT_DIR = \"extracted_frames\" # Updated output directory name\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# --- CONFIGURATION for frame extraction ---\n",
    "FRAME_EXTRACTION_INTERVAL_SECONDS = 2.0\n",
    "\n",
    "if not json_path.exists():\n",
    "    print(f\"Error: JSON file not found at {json_path}\")\n",
    "    exit()\n",
    "print(f\"Loading captions from: {json_path}\")\n",
    "data = load_captions(str(json_path))\n",
    "if not data:\n",
    "    print(\"No data loaded from captions file. Exiting.\")\n",
    "    exit()\n",
    "df = pd.DataFrame(data)\n",
    "if df.empty:\n",
    "    print(\"DataFrame is empty after loading captions. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# --- Filtering logic (same as before to get all potentially valid IDs) ---\n",
    "contains_car = df[df['caption'].str.contains(r'\\bcar\\b', case=False, na=False)]\n",
    "car_video_ids = set(contains_car['video_id'])\n",
    "caption_counts = df['video_id'].value_counts()\n",
    "videos_with_8plus = set(caption_counts[caption_counts > 8].index)\n",
    "valid_video_ids = list(car_video_ids & videos_with_8plus)\n",
    "\n",
    "print(f\"Found {len(valid_video_ids)} potentially valid video IDs based on caption criteria.\")\n",
    "\n",
    "video_id_to_url_map = {}\n",
    "if not df.empty and 'video_id' in df.columns and 'video_url' in df.columns:\n",
    "    temp_df_for_urls = df[df['video_id'].isin(valid_video_ids)][['video_id', 'video_url']].drop_duplicates()\n",
    "    video_id_to_url_map = pd.Series(temp_df_for_urls.video_url.values, index=temp_df_for_urls.video_id).to_dict()\n",
    "else:\n",
    "    print(\"DataFrame is missing 'video_id' or 'video_url' columns. Cannot proceed with URL mapping.\")\n",
    "    exit()\n",
    "\n",
    "# --- Download videos and extract frames using yt-dlp, aiming for 10 successful ones ---\n",
    "TARGET_SUCCESSFUL_VIDEOS = 10\n",
    "successfully_processed_count = 0\n",
    "attempted_video_index = 0\n",
    "successfully_downloaded_ids_and_framesinfo = [] # Store dicts: {'video_id': id, 'num_frames_extracted': count}\n",
    "\n",
    "\n",
    "print(f\"\\nStarting download and frame extraction (every {FRAME_EXTRACTION_INTERVAL_SECONDS}s), aiming for {TARGET_SUCCESSFUL_VIDEOS} successful videos...\")\n",
    "\n",
    "while successfully_processed_count < TARGET_SUCCESSFUL_VIDEOS and attempted_video_index < len(valid_video_ids):\n",
    "    video_id = valid_video_ids[attempted_video_index]\n",
    "    attempted_video_index += 1\n",
    "\n",
    "    url = video_id_to_url_map.get(video_id)\n",
    "    if not url:\n",
    "        print(f\"Could not find URL for video_id: {video_id}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nAttempting to process video {attempted_video_index}/{len(valid_video_ids)} (target {successfully_processed_count+1}/{TARGET_SUCCESSFUL_VIDEOS}): {video_id} from {url}\")\n",
    "    \n",
    "    download_filename_template = f\"{video_id}.mp4\"\n",
    "    # Save downloaded videos temporarily in a subfolder or main output dir\n",
    "    temp_download_dir = os.path.join(OUTPUT_DIR, \"temp_videos\")\n",
    "    os.makedirs(temp_download_dir, exist_ok=True)\n",
    "    local_video_path_template = os.path.join(temp_download_dir, download_filename_template)\n",
    "    \n",
    "    actual_downloaded_video_path = None\n",
    "\n",
    "    ydl_opts = {\n",
    "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',\n",
    "        'outtmpl': local_video_path_template,\n",
    "        'quiet': False, # Set to False to see yt-dlp output, True to suppress\n",
    "        'noplaylist': True,\n",
    "        'socket_timeout': 30,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            print(f\"Downloading video: {video_id} using yt-dlp...\")\n",
    "            info_dict = ydl.extract_info(url, download=True)\n",
    "            actual_downloaded_video_path = ydl.prepare_filename(info_dict)\n",
    "\n",
    "            if not os.path.exists(actual_downloaded_video_path):\n",
    "                 # If outtmpl was fully specified, actual_downloaded_video_path might be it\n",
    "                 if os.path.exists(local_video_path_template):\n",
    "                      actual_downloaded_video_path = local_video_path_template\n",
    "                 else:\n",
    "                      print(f\"Download failed or file not found at expected path for {video_id}.\")\n",
    "                      continue\n",
    "        \n",
    "        print(f\"Downloaded to {actual_downloaded_video_path}\")\n",
    "\n",
    "        print(f\"Extracting frames for {video_id} at ~{FRAME_EXTRACTION_INTERVAL_SECONDS}s intervals...\")\n",
    "        # Create a sub-directory for frames of this specific video\n",
    "        video_frames_output_dir = os.path.join(OUTPUT_DIR, video_id)\n",
    "        os.makedirs(video_frames_output_dir, exist_ok=True)\n",
    "        \n",
    "        frames_extracted_count = 0\n",
    "        with av.open(actual_downloaded_video_path) as container:\n",
    "            stream = container.streams.video[0]\n",
    "            \n",
    "            # Get FPS. stream.average_rate might be Fraction(0, 1) if not available, so try others.\n",
    "            fps = stream.average_rate\n",
    "            if not fps or float(fps) == 0:\n",
    "                fps = stream.guessed_rate\n",
    "            if not fps or float(fps) == 0:\n",
    "                fps = stream.r_frame_rate # Often more reliable\n",
    "            if not fps or float(fps) == 0:\n",
    "                print(f\"Could not determine FPS for {video_id}. Skipping frame extraction.\")\n",
    "                continue\n",
    "            fps = float(fps)\n",
    "            if fps <= 0:\n",
    "                print(f\"Invalid FPS ({fps}) for {video_id}. Skipping frame extraction.\")\n",
    "                continue\n",
    "\n",
    "            frames_to_skip_per_interval = int(round(fps * FRAME_EXTRACTION_INTERVAL_SECONDS))\n",
    "            if frames_to_skip_per_interval <= 0: # Ensure we always advance\n",
    "                frames_to_skip_per_interval = 1\n",
    "            \n",
    "            print(f\"  Video FPS: {fps:.2f}, Extracting 1 frame every {frames_to_skip_per_interval} frames.\")\n",
    "\n",
    "            frame_index_in_video = 0\n",
    "            next_extraction_frame_index = 0\n",
    "\n",
    "            for frame_obj in container.decode(stream):\n",
    "                if frame_index_in_video >= next_extraction_frame_index:\n",
    "                    # Calculate timestamp for the frame filename\n",
    "                    timestamp_seconds = frame_obj.time # frame.time is in seconds\n",
    "                    # Sanitize timestamp for filename (e.g., replace dot with underscore)\n",
    "                    timestamp_str = f\"{timestamp_seconds:.2f}\".replace('.', '_')\n",
    "                    \n",
    "                    out_frame_path = os.path.join(video_frames_output_dir, f\"{video_id}_ts_{timestamp_str}_frame_{frames_extracted_count:04d}.jpg\")\n",
    "                    frame_obj.to_image().save(out_frame_path, quality=80)\n",
    "                    frames_extracted_count += 1\n",
    "                    next_extraction_frame_index += frames_to_skip_per_interval\n",
    "                \n",
    "                frame_index_in_video += 1\n",
    "        \n",
    "        if frames_extracted_count > 0:\n",
    "            print(f\"{frames_extracted_count} frames saved for {video_id} in {video_frames_output_dir}\")\n",
    "            successfully_processed_count += 1\n",
    "            successfully_downloaded_ids_and_framesinfo.append({'video_id': video_id, 'num_frames_extracted': frames_extracted_count, 'frames_path': video_frames_output_dir})\n",
    "        else:\n",
    "            print(f\"No frames extracted for {video_id} despite successful download. Check FPS or video length.\")\n",
    "\n",
    "    except yt_dlp.utils.DownloadError as e_dl:\n",
    "        error_msg = str(e_dl).lower()\n",
    "        if \"video unavailable\" in error_msg: print(f\"Skipping {video_id}: Video is unavailable (yt-dlp).\")\n",
    "        elif \"private video\" in error_msg: print(f\"Skipping {video_id}: Video is private (yt-dlp).\")\n",
    "        elif \"login required\" in error_msg or \"account action required\" in error_msg: print(f\"Skipping {video_id}: Video requires login or account action (yt-dlp).\")\n",
    "        elif \"http error 400\" in error_msg: print(f\"yt-dlp HTTP Error 400 for {video_id}. URL: {url}\")\n",
    "        elif \"http error 403\" in error_msg: print(f\"yt-dlp HTTP Error 403 (Forbidden) for {video_id}. URL: {url}\")\n",
    "        elif \"socket timeout\" in error_msg: print(f\"yt-dlp socket timeout for {video_id}. URL: {url}\")\n",
    "        else: print(f\"yt-dlp download error for {video_id}: {e_dl}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while processing {video_id}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # Print full traceback for unexpected errors\n",
    "    finally:\n",
    "        # Clean up the downloaded video file\n",
    "        if actual_downloaded_video_path and os.path.exists(actual_downloaded_video_path):\n",
    "            try:\n",
    "                print(f\"Cleaning up video file: {actual_downloaded_video_path}\")\n",
    "                os.remove(actual_downloaded_video_path)\n",
    "            except Exception as e_remove:\n",
    "                print(f\"Failed to remove video file {actual_downloaded_video_path}: {e_remove}\")\n",
    "    \n",
    "    # time.sleep(0.5)\n",
    "\n",
    "print(f\"\\nFinished processing loop.\")\n",
    "print(f\"{successfully_processed_count} videos had frames successfully extracted.\")\n",
    "if successfully_processed_count < TARGET_SUCCESSFUL_VIDEOS:\n",
    "    print(f\"Could not reach the target of {TARGET_SUCCESSFUL_VIDEOS} videos. Attempted {attempted_video_index} out of {len(valid_video_ids)} potential videos.\")\n",
    "\n",
    "# --- Information about successfully processed videos and their frames ---\n",
    "if successfully_downloaded_ids_and_framesinfo:\n",
    "    print(\"\\nSummary of successfully processed videos and extracted frames:\")\n",
    "    total_frames_globally = 0\n",
    "    for info in successfully_downloaded_ids_and_framesinfo:\n",
    "        print(f\"  Video ID: {info['video_id']}, Frames Extracted: {info['num_frames_extracted']}, Path: {info['frames_path']}\")\n",
    "        total_frames_globally += info['num_frames_extracted']\n",
    "    print(f\"Total frames extracted across all successful videos: {total_frames_globally}\")\n",
    "\n",
    "    # --- Caption confirmation for videos that had frames extracted ---\n",
    "    video_ids_with_frames = [info['video_id'] for info in successfully_downloaded_ids_and_framesinfo]\n",
    "    if not df.empty and 'video_id' in df.columns:\n",
    "        selected_captions_df = df[df['video_id'].isin(video_ids_with_frames)]\n",
    "        if not selected_captions_df.empty:\n",
    "            print(f\"\\nSelected {len(selected_captions_df)} captions from the {len(video_ids_with_frames)} videos that had frames extracted:\")\n",
    "            print(selected_captions_df.groupby(\"video_id\").size())\n",
    "        else:\n",
    "            print(\"\\nNo captions found in the dataframe for the videos that had frames extracted.\")\n",
    "else:\n",
    "    print(\"\\nNo videos were successfully downloaded and/or no frames were extracted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5df79b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-cv-ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
