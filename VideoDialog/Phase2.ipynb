{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c31b05",
   "metadata": {},
   "source": [
    "# Phase2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02289b93",
   "metadata": {},
   "source": [
    "# Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba621c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pprint as pp\n",
    "import requests\n",
    "\n",
    "host = 'api.novasearch.org'\n",
    "port = 443\n",
    "\n",
    "user = 'user02' # Add your user name here.\n",
    "password = 'marco.2025+' # Add your user password here. For testing only. Don't store credentials in code. \n",
    "index_name = user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1348fa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: HTTPConnectionPool(host='localhost', port=9200): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000024ED1764970>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings()  # Suppress self-signed cert warnings\n",
    "\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import requests\n",
    "import pprint as pp\n",
    "\n",
    "host = 'localhost'\n",
    "port = 9200\n",
    "user = 'admin'\n",
    "password = 'MyStr0ng@Pass'\n",
    "index_name = user\n",
    "\n",
    "url = f\"http://{host}:{port}\"\n",
    "\n",
    "try:\n",
    "    res = requests.get(url, auth=HTTPBasicAuth(user, password), verify=False)\n",
    "    pp.pprint(res.json())\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Request failed:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0ce917",
   "metadata": {},
   "source": [
    "# Frame Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42f3893f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting video processing (aiming for 10 successful videos)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] MWdPh6J-YXM: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID v_MWdPh6J-YXM: Failed - Private video.\n",
      "Video ID v_1LdbczjQPII: Success - 82 frames extracted.     \n",
      "Video ID v_uICwWvS_AOo: Success - 96 frames extracted.     \n",
      "Video ID v_Gms3Yt6RrV4: Success - 75 frames extracted.     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] amCD-2TIKw0: Video unavailable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID v_amCD-2TIKw0: Failed - Video unavailable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] jPLJAYnjsBw: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID v_jPLJAYnjsBw: Failed - Private video.\n",
      "Video ID v_Eilil6FZhK8: Success - 110 frames extracted.    \n",
      "Video ID v_9DVsv84awMg: Success - 107 frames extracted.    \n",
      "Video ID v_9hR1MHvXGv8: Success - 57 frames extracted.     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] S5kuckj4Ud4: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID v_S5kuckj4Ud4: Failed - Private video.\n",
      "Video ID v_9V7cMp_w1_0: Success - 89 frames extracted.                   \n",
      "Video ID v_06ofnvq2Hjs: Success - 102 frames extracted.    \n",
      "\n",
      "Finished processing loop.\n",
      "8 of 12 attempted videos had frames successfully extracted.\n",
      "Target of 10 successful videos not reached. All 12 potential videos processed.\n",
      "\n",
      "Summary of successfully processed videos:\n",
      "  - Video ID: v_1LdbczjQPII, Frames Extracted: 82\n",
      "  - Video ID: v_uICwWvS_AOo, Frames Extracted: 96\n",
      "  - Video ID: v_Gms3Yt6RrV4, Frames Extracted: 75\n",
      "  - Video ID: v_Eilil6FZhK8, Frames Extracted: 110\n",
      "  - Video ID: v_9DVsv84awMg, Frames Extracted: 107\n",
      "  - Video ID: v_9hR1MHvXGv8, Frames Extracted: 57\n",
      "  - Video ID: v_9V7cMp_w1_0, Frames Extracted: 89\n",
      "  - Video ID: v_06ofnvq2Hjs, Frames Extracted: 102\n",
      "\n",
      "Total frames extracted across all successful videos: 718\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import yt_dlp\n",
    "import av # For frame extraction\n",
    "import os\n",
    "import time\n",
    "import math # For ceiling function if needed for frame counts\n",
    "\n",
    "# --- Provided load_captions function (remains the same) ---\n",
    "def load_captions(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    result = []\n",
    "    for vid_key, meta_info in data.items():\n",
    "        if isinstance(meta_info, dict) and 'timestamps' in meta_info and 'sentences' in meta_info:\n",
    "            for (start, end), sentence in zip(meta_info['timestamps'], meta_info['sentences']):\n",
    "                result.append({\n",
    "                    \"video_id\": vid_key,\n",
    "                    \"duration\": meta_info.get(\"duration\", 0),\n",
    "                    \"start\": start,\n",
    "                    \"end\": end,\n",
    "                    \"caption\": sentence,\n",
    "                    \"video_url\": f\"https://www.youtube.com/watch?v={vid_key[2:]}\" if vid_key.startswith(\"v_\") else f\"https://www.youtube.com/watch?v={vid_key}\"\n",
    "                })\n",
    "        # else:\n",
    "            # print(f\"Warning: Skipping entry {vid_key} in load_captions due to unexpected structure or missing keys.\")\n",
    "    return result\n",
    "\n",
    "# --- Setup ---\n",
    "repo_root = Path().resolve()\n",
    "json_path = repo_root / \"captions\" / \"train.json\"\n",
    "OUTPUT_DIR = \"extracted_frames\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# --- CONFIGURATION for frame extraction ---\n",
    "FRAME_EXTRACTION_INTERVAL_SECONDS = 2.0\n",
    "\n",
    "if not json_path.exists():\n",
    "    print(f\"Error: JSON file not found at {json_path}\")\n",
    "    exit()\n",
    "# print(f\"Loading captions from: {json_path}\") # Reduced verbosity\n",
    "data = load_captions(str(json_path))\n",
    "if not data:\n",
    "    print(\"No data loaded from captions file. Exiting.\")\n",
    "    exit()\n",
    "df = pd.DataFrame(data)\n",
    "if df.empty:\n",
    "    print(\"DataFrame is empty after loading captions. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# --- Filtering logic ---\n",
    "contains_car = df[df['caption'].str.contains(r'\\bcar\\b', case=False, na=False)]\n",
    "car_video_ids = set(contains_car['video_id'])\n",
    "caption_counts = df['video_id'].value_counts()\n",
    "videos_with_8plus = set(caption_counts[caption_counts > 8].index)\n",
    "valid_video_ids = list(car_video_ids & videos_with_8plus)\n",
    "\n",
    "# print(f\"Found {len(valid_video_ids)} potentially valid video IDs based on caption criteria.\") # Reduced verbosity\n",
    "\n",
    "video_id_to_url_map = {}\n",
    "if not df.empty and 'video_id' in df.columns and 'video_url' in df.columns:\n",
    "    temp_df_for_urls = df[df['video_id'].isin(valid_video_ids)][['video_id', 'video_url']].drop_duplicates()\n",
    "    video_id_to_url_map = pd.Series(temp_df_for_urls.video_url.values, index=temp_df_for_urls.video_id).to_dict()\n",
    "else:\n",
    "    print(\"DataFrame is missing 'video_id' or 'video_url' columns. Cannot proceed with URL mapping.\")\n",
    "    exit()\n",
    "\n",
    "# --- Download videos and extract frames ---\n",
    "TARGET_SUCCESSFUL_VIDEOS = 10\n",
    "successfully_processed_count = 0\n",
    "attempted_video_index = 0\n",
    "successfully_downloaded_ids_and_framesinfo = []\n",
    "\n",
    "print(f\"\\nStarting video processing (aiming for {TARGET_SUCCESSFUL_VIDEOS} successful videos)...\")\n",
    "\n",
    "while successfully_processed_count < TARGET_SUCCESSFUL_VIDEOS and attempted_video_index < len(valid_video_ids):\n",
    "    video_id = valid_video_ids[attempted_video_index]\n",
    "    attempted_video_index += 1\n",
    "\n",
    "    url = video_id_to_url_map.get(video_id)\n",
    "    if not url:\n",
    "        print(f\"Video ID {video_id}: Could not find URL. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # print(f\"\\nAttempting to process video {attempted_video_index}/{len(valid_video_ids)} (target {successfully_processed_count+1}/{TARGET_SUCCESSFUL_VIDEOS}): {video_id}\") # Reduced verbosity\n",
    "    \n",
    "    download_filename_template = f\"{video_id}.mp4\"\n",
    "    temp_download_dir = os.path.join(OUTPUT_DIR, \"temp_videos\")\n",
    "    os.makedirs(temp_download_dir, exist_ok=True)\n",
    "    local_video_path_template = os.path.join(temp_download_dir, download_filename_template)\n",
    "    \n",
    "    actual_downloaded_video_path = None\n",
    "\n",
    "    ydl_opts = {\n",
    "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',\n",
    "        'outtmpl': local_video_path_template,\n",
    "        'quiet': True, # Suppress yt-dlp console output\n",
    "        'noplaylist': True,\n",
    "        'socket_timeout': 30,\n",
    "        'logtostderr': False, # Don't log to stderr when quiet\n",
    "        'no_warnings': True, # Suppress warnings when quiet\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # print(f\"Processing video: {video_id}...\") # Reduced verbosity, combined below\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            info_dict = ydl.extract_info(url, download=True)\n",
    "            actual_downloaded_video_path = ydl.prepare_filename(info_dict)\n",
    "\n",
    "            if not os.path.exists(actual_downloaded_video_path):\n",
    "                 if os.path.exists(local_video_path_template):\n",
    "                      actual_downloaded_video_path = local_video_path_template\n",
    "                 else:\n",
    "                      print(f\"Video ID {video_id}: Download failed or file not found.\")\n",
    "                      continue\n",
    "        \n",
    "        # print(f\"Downloaded {video_id} to {actual_downloaded_video_path}\") # Reduced verbosity\n",
    "\n",
    "        # print(f\"Extracting frames for {video_id}...\") # Reduced verbosity\n",
    "        video_frames_output_dir = os.path.join(OUTPUT_DIR, video_id)\n",
    "        os.makedirs(video_frames_output_dir, exist_ok=True)\n",
    "        \n",
    "        frames_extracted_count = 0\n",
    "        with av.open(actual_downloaded_video_path) as container:\n",
    "            stream = container.streams.video[0]\n",
    "            fps = stream.average_rate\n",
    "            if not fps or float(fps) == 0: fps = stream.guessed_rate\n",
    "            if not fps or float(fps) == 0: fps = stream.r_frame_rate\n",
    "            if not fps or float(fps) == 0:\n",
    "                print(f\"Video ID {video_id}: Could not determine FPS. Skipping frame extraction.\")\n",
    "                continue\n",
    "            fps = float(fps)\n",
    "            if fps <= 0:\n",
    "                print(f\"Video ID {video_id}: Invalid FPS ({fps}). Skipping frame extraction.\")\n",
    "                continue\n",
    "\n",
    "            frames_to_skip_per_interval = int(round(fps * FRAME_EXTRACTION_INTERVAL_SECONDS))\n",
    "            if frames_to_skip_per_interval <= 0: frames_to_skip_per_interval = 1\n",
    "            \n",
    "            # print(f\"  Video FPS: {fps:.2f}, Extracting 1 frame every {frames_to_skip_per_interval} frames.\") # Reduced verbosity\n",
    "\n",
    "            frame_index_in_video = 0\n",
    "            next_extraction_frame_index = 0\n",
    "\n",
    "            for frame_obj in container.decode(stream):\n",
    "                if frame_index_in_video >= next_extraction_frame_index:\n",
    "                    timestamp_seconds = frame_obj.time\n",
    "                    timestamp_str = f\"{timestamp_seconds:.2f}\".replace('.', '_')\n",
    "                    out_frame_path = os.path.join(video_frames_output_dir, f\"{video_id}_ts_{timestamp_str}_frame_{frames_extracted_count:04d}.jpg\")\n",
    "                    frame_obj.to_image().save(out_frame_path, quality=80)\n",
    "                    frames_extracted_count += 1\n",
    "                    next_extraction_frame_index += frames_to_skip_per_interval\n",
    "                frame_index_in_video += 1\n",
    "        \n",
    "        if frames_extracted_count > 0:\n",
    "            print(f\"Video ID {video_id}: Success - {frames_extracted_count} frames extracted.\")\n",
    "            successfully_processed_count += 1\n",
    "            successfully_downloaded_ids_and_framesinfo.append({'video_id': video_id, 'num_frames_extracted': frames_extracted_count, 'frames_path': video_frames_output_dir})\n",
    "        else:\n",
    "            print(f\"Video ID {video_id}: Downloaded but no frames extracted (check FPS/length).\")\n",
    "\n",
    "    except yt_dlp.utils.DownloadError as e_dl:\n",
    "        error_msg = str(e_dl).lower()\n",
    "        # Simplified error reporting\n",
    "        if \"video unavailable\" in error_msg: print(f\"Video ID {video_id}: Failed - Video unavailable.\")\n",
    "        elif \"private video\" in error_msg: print(f\"Video ID {video_id}: Failed - Private video.\")\n",
    "        elif \"login required\" in error_msg or \"account action required\" in error_msg: print(f\"Video ID {video_id}: Failed - Login/account action required.\")\n",
    "        elif \"http error 400\" in error_msg: print(f\"Video ID {video_id}: Failed - HTTP Error 400.\")\n",
    "        elif \"http error 403\" in error_msg: print(f\"Video ID {video_id}: Failed - HTTP Error 403 (Forbidden).\")\n",
    "        elif \"socket timeout\" in error_msg: print(f\"Video ID {video_id}: Failed - Socket timeout.\")\n",
    "        else: print(f\"Video ID {video_id}: Failed - yt-dlp download error: {e_dl}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Video ID {video_id}: Failed - Unexpected error: {e}\")\n",
    "        # import traceback # Optionally keep for debugging\n",
    "        # traceback.print_exc()\n",
    "    finally:\n",
    "        if actual_downloaded_video_path and os.path.exists(actual_downloaded_video_path):\n",
    "            try:\n",
    "                # print(f\"Cleaning up video file: {actual_downloaded_video_path}\") # Reduced verbosity\n",
    "                os.remove(actual_downloaded_video_path)\n",
    "            except Exception as e_remove:\n",
    "                print(f\"Warning: Failed to remove video file {actual_downloaded_video_path}: {e_remove}\")\n",
    "    \n",
    "    # time.sleep(0.5) # Keep if desired for rate limiting\n",
    "\n",
    "print(f\"\\nFinished processing loop.\")\n",
    "print(f\"{successfully_processed_count} of {attempted_video_index} attempted videos had frames successfully extracted.\")\n",
    "if successfully_processed_count < TARGET_SUCCESSFUL_VIDEOS and attempted_video_index == len(valid_video_ids):\n",
    "    print(f\"Target of {TARGET_SUCCESSFUL_VIDEOS} successful videos not reached. All {len(valid_video_ids)} potential videos processed.\")\n",
    "elif successfully_processed_count < TARGET_SUCCESSFUL_VIDEOS:\n",
    "     print(f\"Target of {TARGET_SUCCESSFUL_VIDEOS} successful videos not reached.\")\n",
    "\n",
    "\n",
    "if successfully_downloaded_ids_and_framesinfo:\n",
    "    print(\"\\nSummary of successfully processed videos:\")\n",
    "    total_frames_globally = 0\n",
    "    for info in successfully_downloaded_ids_and_framesinfo:\n",
    "        # Path is removed for less verbosity, can be added back if needed\n",
    "        print(f\"  - Video ID: {info['video_id']}, Frames Extracted: {info['num_frames_extracted']}\")\n",
    "        total_frames_globally += info['num_frames_extracted']\n",
    "    print(f\"\\nTotal frames extracted across all successful videos: {total_frames_globally}\")\n",
    "else:\n",
    "    print(\"\\nNo videos were successfully processed or no frames were extracted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5df79b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-cv-ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
